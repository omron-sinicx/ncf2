name: "ncf2"
algo: "sac"
agent_type: "coop"
gamma: 0.95
tau: 0.005
alpha: 0.2
target_update_interval: 1
automatic_entropy_tuning: True
hidden_dim: 256
msg_dim: 24
pos_dim: 3
action_dim: 2
is_discrete: True
actor_lr: 0.001
critic_lr: 0.001
alpha_lr: 0.001
batch_size: 256
minibatch_size: 256
save_interval: 10000
fov_size: 100
backup_entropy: True
use_jax: True
auto_temp_tuning: True
pos_type: traj
traj_length: 1
use_meta_policy: True
# mask
mask_neighbor: True
mask_priority: False
r: 0.15
# buffer
buffer_alpha: 0.6
beta_start: 0.4
beta_frames: 100000
memory_size: 1500000
use_per: False
# reward shaping
use_ineq_aversion: False
ineq_alpha: 0
ineq_beta: 0
#meta policy
coop_actor_lr: 0.001
coop_critic_lr: 0.001
coop_alpha_lr: 0.001
random_act_iter: 20000
coop_crash_penalty: 0
coop_goal_reward: 0
coop_alpha: -0.1
coop_beta: 0.5
use_relative_penalty: True
use_regret_penalty: True
use_env_reward: False
use_improve: True
use_diff_relative: True
use_fix_prio: False
# train
horizon: 500000
update_interval: 1
num_collect_data: 100000
eval_interval: 250
eval_iters: 50
num_average_episodes: 500
render_interval: 1000
num_actors: 1
pretrain_iters: 7000
warmup_iters: 10000
train_sub_model: True
use_trained_model: True
stop_rate: 0.05
joint_train: True
